{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# Наивный классификатор Байеса"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## 0 Импорт необходимых библиотек"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from typing import Iterable, Dict, Union, List\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## 1 Naive Bayes with distributions\n",
        "\n",
        "Разбить данные на тренировочную и тестовую выборки.\n",
        "На основе обучающей создать модель наивного байеса, используя данное соотношение:\n",
        "\n",
        "$P(class | x_1, x_2, \\dots, x_n) = P(x_1|class) \\cdot P(x_2|class) \\cdot ... \\cdot P(x_n|class) \\cdot P(class)$\n",
        "\n",
        "На тестовой выборке посчитать accuracy, precision и recall.\n",
        "\n",
        "Если в данных содержатся числовые признаки, то предполагать для них нормальное распределение: \n",
        "\n",
        "$\\mu = \\frac{1}{n}\\sum\\limits_{i=1}^{n} x_i$ – среднее\n",
        "\n",
        "$\\sigma = \\left[ \\frac{1}{n-1} \\sum\\limits_{i=1}^{n} (x_i - \\mu)^2 \\right]^{0.5}$ – стандартное отклонение\n",
        "\n",
        "$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp({-\\frac{(x-\\mu)^2}{2\\sigma^2})}$ – функция плотности для нормального распределения"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 1.1 Naive Bayes from Scratch (normal distribution incl.)"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# noinspection PyMethodMayBeStatic, PyPep8Naming, PyShadowingNames\n",
        "class NaiveBayesFromScratch:\n",
        "    def __init__(self, num_features_cols: List[int], num_strategy=\"split\"):\n",
        "        self._classes_counts: Dict[Union[str, int], int] = dict()\n",
        "        self._classes_probas: Dict[Union[str, int], float] = dict()\n",
        "        self._features_probas_if_class: Dict[int, Dict[int, Dict[Union[str, int], float]]] = {}\n",
        "        self._features_bins: np.ndarray = np.array([])\n",
        "        self.num_features_cols: List[int] = num_features_cols\n",
        "        self.num_strategy: str = num_strategy\n",
        "        if self.num_strategy == \"split\":\n",
        "            # Means & standard deviations for numeric features (index match by self.num_features)\n",
        "            self._means: Dict[Union[str, int], np.ndarray] = {}\n",
        "            self._stds: Dict[Union[str, int], np.ndarray] = {}\n",
        "\n",
        "    def fit(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
        "        self._count_classes_probas(y_train)\n",
        "        if self.num_strategy == \"split\":\n",
        "            X_train = self._split_numeric_features(X_train)\n",
        "        else:\n",
        "            self._means, self._stds = self._count_distribution_params(X_train, y_train)\n",
        "        self._count_features_if_class_probas(X_train, y_train)\n",
        "\n",
        "    def _count_classes_probas(self, y_train: np.ndarray) -> None:\n",
        "        self._classes_counts = Counter(y_train)\n",
        "        for label, value in self._classes_counts.items():\n",
        "            self._classes_probas[label] = value \/ len(y_train)\n",
        "\n",
        "    def _split_numeric_features(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Split given numeric features into quartiles\n",
        "           and modify given X by adding four new binary features\n",
        "           (boundaries: 25%, 50%, 75%)\"\"\"\n",
        "\n",
        "        if self._features_bins.size == 0:\n",
        "            self._features_bins = np.percentile(X[:, self.num_features_cols],\n",
        "                                                q=(0, 25, 50, 75, 100),\n",
        "                                                axis=0)\n",
        "\n",
        "        for col_idx, bins in enumerate(self._features_bins.transpose()):\n",
        "            values = X[:, self.num_features_cols[col_idx]]\n",
        "            for i in range(bins.size - 1):\n",
        "                if i == bins.size - 1:\n",
        "                    is_between = (values > bins[i]) & (values <= bins[i + 1])\n",
        "                else:\n",
        "                    is_between = (values >= bins[i]) & (values < bins[i + 1])\n",
        "                X = np.column_stack((X, is_between))\n",
        "\n",
        "        return np.delete(X, self.num_features_cols, axis=1)\n",
        "    \n",
        "    def _count_distribution_params(self, \n",
        "                                   X: np.ndarray, \n",
        "                                   y: np.ndarray) -> Iterable[Dict[Union[str, int], np.ndarray]]:\n",
        "        return {label : np.mean(X[:, self.num_features_cols][y_train == label], axis=0) for label in np.unique(y)}, \\\n",
        "               {label : np.std(X[:, self.num_features_cols][y_train == label], axis=0) for label in np.unique(y)}\n",
        "\n",
        "    def _count_features_if_class_probas(self,\n",
        "                                        X_train: np.ndarray,\n",
        "                                        y_train: np.ndarray) -> None:\n",
        "        for label in self._classes_counts:\n",
        "            for feature_idx, feature in enumerate(X_train.transpose()):\n",
        "                if self.num_strategy == \"dist\" and feature_idx in self.num_features_cols:\n",
        "                    pass\n",
        "                else:\n",
        "                    for value in np.unique(feature):\n",
        "                        self._features_probas_if_class.setdefault(label, dict()).setdefault(feature_idx, dict())[value] = \\\n",
        "                            np.sum((X_train[:, feature_idx] == value) & (y_train == label)) \/ self._classes_counts[label]\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> Iterable[np.ndarray]:\n",
        "        if self.num_strategy == \"split\":\n",
        "            X_test = self._split_numeric_features(X_test)\n",
        "        predicted_labels, predicted_dist = np.array([]), np.array([])\n",
        "        for instance in X_test:\n",
        "            predicted_label, inst_dist = self._predict_single(instance)\n",
        "            predicted_dist = inst_dist if predicted_dist.size == 0 else np.row_stack((predicted_dist, inst_dist))\n",
        "            predicted_labels = np.hstack((predicted_labels, predicted_label))\n",
        "        return predicted_labels, predicted_dist\n",
        "\n",
        "    def _predict_single(self, instance: np.ndarray) -> Iterable[np.ndarray]:\n",
        "        labels_dist = []\n",
        "        for label, label_proba in self._classes_probas.items():\n",
        "            predicted_proba = label_proba\n",
        "            for idx, value in enumerate(instance):\n",
        "                if self.num_strategy == \"dist\" and idx in self.num_features_cols:\n",
        "                    real_idx = self.num_features_cols.index(idx)\n",
        "                    mean, std = self._means[label][real_idx], self._stds[label][real_idx]\n",
        "                    value_proba = np.exp((-1 * (value - mean) ** 2) \/ (2 * std ** 2)) \/ (std * np.sqrt(np.pi))\n",
        "                else:\n",
        "                    value_proba = self._features_probas_if_class[label][idx].get(value, 10 ** (-5))\n",
        "                predicted_proba *= value_proba\n",
        "            labels_dist.append((label, predicted_proba))\n",
        "        return np.array(max(labels_dist, key=lambda t: t[1])[0]), np.array(labels_dist)\n",
        "\n",
        "    def accuracy_score(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "        return metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "    def precision_score(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "        return metrics.precision_score(y_true, y_pred)\n",
        "\n",
        "    def recall_score(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "        return metrics.recall_score(y_true, y_pred)\n",
        "\n",
        "    def all_scores(self, y_true: np.ndarray, y_pred: np.ndarray) -> Iterable[float]:\n",
        "        \"\"\"Return accuracy, precision and recall scores on given labels\"\"\"\n",
        "        return self.accuracy_score(y_true, y_pred), self.precision_score(y_true, y_pred), \\\n",
        "               self.recall_score(y_true, y_pred)"
      ],
      "execution_count":61,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 1.2 Подготовка данных"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "url = 'https:\/\/raw.githubusercontent.com\/otverskoj\/First-steps-in-Data-Analysis\/main\/datasets\/classification\/occupancy_detection_preprocessed.csv'\n",
        "names = ['date', 'temperature', 'humidity', 'light', 'co2', 'humidity_ratio', 'occupancy']\n",
        "df = pd.read_csv(url, names=names, skiprows=1).drop(['date'], axis=1).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "X, y = df.drop([\"occupancy\"], axis=1).values, df.loc[:, \"occupancy\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
      ],
      "execution_count":35,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 1.3 Апробация на своих данных"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "num_cols = list(range(X.shape[1]))\n",
        "bayes = NaiveBayesFromScratch(num_cols, num_strategy=\"dist\")\n",
        "bayes.fit(X_train, y_train)\n",
        "y_pred, _ = bayes.predict(X_test)\n",
        "print(\"Accuracy: \", bayes.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision: \", bayes.precision_score(y_test, y_pred))\n",
        "print(\"Recall: \", bayes.recall_score(y_test, y_pred))"
      ],
      "execution_count":62,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Accuracy:  0.9686770428015564\n",
            "Precision:  0.8817843866171003\n",
            "Recall:  0.9983164983164983\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}